# Customer Churn Prediction - MLOps Project

An end-to-end MLOps project for predicting customer churn using machine learning, with complete CI/CD pipeline, containerization, and cloud deployment.

## ğŸ“‹ Project Overview

This project demonstrates a production-ready ML system with:
- **Multiple ML Models**: Logistic Regression, Random Forest, XGBoost, LightGBM
- **Experiment Tracking**: MLflow for comprehensive tracking
- **Complete Testing**: Unit, integration, and data quality tests
- **Containerization**: Docker & Docker Hub
- **Orchestration**: Kubernetes deployment
- **CI/CD**: GitHub Actions automation
- **Cloud Deployment**: AWS (EKS, S3, ECR)
- **Monitoring**: Model performance tracking

## ğŸ¯ Business Problem

Predict customer churn to enable proactive retention strategies, reducing customer attrition by 15% and improving customer lifetime value.

## ğŸ“Š Dataset

- **Source**: Telco Customer Churn Dataset
- **Size**: ~7000 customers
- **Features**: 20 features (demographics, services, contract details)
- **Target**: Binary classification (Churn: Yes/No)

## ğŸ—ï¸ Project Structure

```
mlops-churn-prediction/
â”‚
â”œâ”€â”€ config/                  # Configuration files
â”‚   â”œâ”€â”€ config.yaml         # Main configuration
â”‚   â””â”€â”€ model_config.yaml   # Model hyperparameters
â”‚
â”œâ”€â”€ data/                   # Data storage (not in git)
â”‚   â”œâ”€â”€ raw/               # Original data
â”‚   â””â”€â”€ processed/         # Cleaned data
â”‚
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ components/        # ML components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”‚   â”œâ”€â”€ data_validation.py
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”‚   â””â”€â”€ model_evaluation.py
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/          # ML pipelines
â”‚   â”‚   â””â”€â”€ training_pipeline.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/             # Utility functions
â”‚   â”œâ”€â”€ config.py          # Configuration manager
â”‚   â”œâ”€â”€ logger.py          # Logging setup
â”‚   â””â”€â”€ exception.py       # Custom exceptions
â”‚
â”œâ”€â”€ scripts/               # Executable scripts
â”‚   â”œâ”€â”€ download_data.py  # Download dataset
â”‚   â””â”€â”€ train.py          # Run training pipeline
â”‚
â”œâ”€â”€ artifacts/            # Generated artifacts (not in git)
â”‚   â”œâ”€â”€ models/          # Trained models
â”‚   â”œâ”€â”€ preprocessors/   # Data transformers
â”‚   â””â”€â”€ metrics/         # Evaluation metrics
â”‚
â”œâ”€â”€ mlruns/              # MLflow tracking (not in git)
â”œâ”€â”€ logs/                # Application logs (not in git)
â”œâ”€â”€ tests/               # Test suite (Phase 4)
â””â”€â”€ requirements.txt     # Python dependencies
```

## ğŸš€ Phase 1: Foundation (COMPLETED)

### Features Implemented

âœ… **Data Pipeline**
- Automated data ingestion with train/test split
- Schema validation and data quality checks
- Feature engineering and preprocessing
- Data transformation pipelines

âœ… **Model Training**
- Multiple model training (4 algorithms)
- Hyperparameter configuration
- Stratified sampling for balanced splits
- Automated model saving

âœ… **Experiment Tracking**
- MLflow integration
- Parameter logging
- Metric tracking
- Model versioning

âœ… **Model Evaluation**
- Comprehensive metrics (Accuracy, Precision, Recall, F1, ROC-AUC)
- Confusion matrix analysis
- Model comparison
- Best model selection

âœ… **Configuration Management**
- YAML-based configuration
- Centralized config manager
- Environment-specific settings

âœ… **Logging & Error Handling**
- Structured logging
- Custom exception handling
- Detailed error tracking

## ğŸ› ï¸ Installation & Setup

### Prerequisites
- Python 3.8+
- pip
- Git

### 1. Clone the Repository
```bash
git clone <your-repo-url>
cd mlops-churn-prediction
```

### 2. Create Virtual Environment
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Create Directory Structure
```bash
# Directories will be created automatically, but you can manually create them:
mkdir -p data/raw data/processed artifacts/models artifacts/preprocessors artifacts/metrics logs mlruns
```

## ğŸ“¥ Download Dataset

### Option 1: Automatic Download (Recommended)
```bash
python scripts/download_data.py
```

### Option 2: Manual Download
1. Visit: https://www.kaggle.com/datasets/blastchar/telco-customer-churn
2. Download the dataset
3. Save as: `data/raw/churn_data.csv`

### Option 3: Kaggle API
```bash
# Install Kaggle
pip install kaggle

# Set up credentials (~/.kaggle/kaggle.json)
# Then run:
python scripts/download_data.py
```

## ğŸ¯ Run Training Pipeline

### Execute Complete Pipeline
```bash
python scripts/train.py
```

### What Happens:
1. **Data Ingestion**: Loads and splits data (80/20)
2. **Data Validation**: Checks schema and quality
3. **Data Preprocessing**: Cleans and transforms features
4. **Model Training**: Trains 4 models with MLflow tracking
5. **Model Evaluation**: Compares models and selects best

### Expected Output:
```
======================================================================
TRAINING PIPELINE COMPLETED SUCCESSFULLY!
======================================================================

Best Model: xgboost
Models trained: 4
Preprocessor saved at: artifacts/preprocessors/preprocessor.pkl

Check MLflow UI for detailed experiment tracking:
  Run: mlflow ui
  Open: http://localhost:5000
======================================================================
```

## ğŸ“Š View Experiments with MLflow

### Start MLflow UI
```bash
mlflow ui
```

### Access Dashboard
Open browser: http://localhost:5000

### What You'll See:
- All experiment runs
- Parameters for each model
- Metrics (accuracy, precision, recall, F1, ROC-AUC)
- Model artifacts
- Comparison charts

## ğŸ“ˆ Evaluation Metrics

### Model Performance Targets
- **Recall**: â‰¥ 80% (catch most churners)
- **Precision**: â‰¥ 70% (avoid false alarms)
- **F1-Score**: â‰¥ 0.75
- **ROC-AUC**: â‰¥ 0.85

### Metrics Calculated
- Accuracy
- Precision, Recall, F1-Score
- ROC-AUC
- Confusion Matrix
- Specificity, Sensitivity
- Classification Report

### View Results
```bash
# Check evaluation report
cat artifacts/metrics/evaluation_report.json

# Check validation report
cat artifacts/validation_report.json
```

## ğŸ”§ Configuration

### Main Configuration (`config/config.yaml`)
- Data paths
- Train/test split ratio
- Feature lists
- Artifact locations
- MLflow settings

### Model Configuration (`config/model_config.yaml`)
- Hyperparameters for each model
- Algorithm-specific settings
- Training parameters

## ğŸ“ Logs

### Log Files
Logs are saved in: `logs/`

### Log Format
```
[2024-11-04 10:30:45] INFO - ChurnPrediction - Starting training pipeline
[2024-11-04 10:30:46] INFO - ChurnPrediction - Data loaded: (7043, 21)
```

## ğŸ§ª Generated Artifacts

### After Training:
```
artifacts/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ logistic_regression.pkl
â”‚   â”œâ”€â”€ random_forest.pkl
â”‚   â”œâ”€â”€ xgboost.pkl
â”‚   â””â”€â”€ lightgbm.pkl
â”œâ”€â”€ preprocessors/
â”‚   â”œâ”€â”€ preprocessor.pkl
â”‚   â””â”€â”€ preprocessor_label_encoder.pkl
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ evaluation_report.json
â””â”€â”€ validation_report.json
```

## ğŸ“ Model Training Details

### Models Trained:
1. **Logistic Regression** (Baseline)
2. **Random Forest** (Ensemble)
3. **XGBoost** (Gradient Boosting)
4. **LightGBM** (Fast Gradient Boosting)

### Training Process:
- Stratified train/test split (80/20)
- Standard scaling for numerical features
- One-hot encoding for categorical features
- Automated hyperparameter configuration
- MLflow tracking for all experiments

## ğŸ”„ Next Phases

### Phase 2: API & UI Development
- [ ] FastAPI REST endpoints
- [ ] Streamlit dashboard
- [ ] Real-time predictions
- [ ] Model serving

### Phase 3: Containerization
- [ ] Dockerfile creation
- [ ] Docker Compose setup
- [ ] Push to Docker Hub

### Phase 4: Testing Suite
- [ ] Unit tests
- [ ] Integration tests
- [ ] Data quality tests
- [ ] Model performance tests

### Phase 5: CI/CD
- [ ] GitHub Actions workflows
- [ ] Automated testing
- [ ] Automated builds

### Phase 6: Cloud Deployment
- [ ] Kubernetes manifests
- [ ] AWS EKS deployment
- [ ] Monitoring setup

## ğŸ› Troubleshooting

### Issue: Dataset not found
```bash
python scripts/download_data.py
```

### Issue: Import errors
```bash
pip install -r requirements.txt
```

### Issue: MLflow UI not starting
```bash
# Check if port 5000 is available
# Or specify different port:
mlflow ui --port 5001
```

### Issue: Memory errors
- Reduce dataset size for testing
- Use smaller model hyperparameters
- Increase system memory

## ğŸ“š Documentation

### Code Documentation
- All functions have docstrings
- Type hints for better IDE support
- Comprehensive comments

### Configuration Documentation
- YAML files with inline comments
- Example configurations provided

## ğŸ¤ Contributing

### Code Style
- Follow PEP 8
- Use type hints
- Write docstrings
- Add logging

### Testing
- Write tests for new features
- Ensure all tests pass
- Maintain code coverage

## ğŸ“„ License

This project is for educational purposes.

## ğŸ‘¥ Authors

Your Name - MLOps Engineer

## ğŸ™ Acknowledgments

- Kaggle for the dataset
- MLflow for experiment tracking
- Scikit-learn, XGBoost, LightGBM communities

---
