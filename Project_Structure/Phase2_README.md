# Phase 2: API & UI Development - Complete Guide

## ğŸ¯ Overview

Phase 2 adds **FastAPI REST API** and **Streamlit Dashboard** for real-time predictions and interactive visualizations.

---

## ğŸ“¦ New Components Added

### 1. **Prediction Pipeline** (`src/pipeline/prediction_pipeline.py`)
- Loads trained models for inference
- Handles single and batch predictions
- Calculates risk levels
- Feature importance extraction

### 2. **FastAPI REST API** (`api/`)
- RESTful endpoints for predictions
- Request/response validation with Pydantic
- Auto-generated API documentation
- Health checks and monitoring

### 3. **Streamlit Dashboard** (`streamlit_app/`)
- Interactive web interface
- Single customer prediction
- Batch CSV upload
- Visualizations and analytics

---

## ğŸš€ Quick Start

### Step 1: Install New Dependencies
```bash
pip install --upgrade pip
pip install fastapi uvicorn[standard] streamlit plotly python-multipart
```

Or install from updated requirements.txt:
```bash
pip install -r requirements.txt
```

### Step 2: Ensure Model is Trained
```bash
# If you haven't trained models yet
python scripts/train.py
```

### Step 3: Start the FastAPI Server
```bash
python run_api.py
```

**API will be available at:**
- Main API: http://localhost:8000
- Interactive Docs: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### Step 4: Start the Streamlit Dashboard (New Terminal)
```bash
python run_streamlit.py
```

**Dashboard will open at:** http://localhost:8501

---

## ğŸ“¡ API Endpoints

### **1. Health Check**
```bash
GET http://localhost:8000/health
```

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "preprocessor_loaded": true,
  "api_version": "1.0.0"
}
```

### **2. Single Prediction**
```bash
POST http://localhost:8000/predict
```

**Request Body:**
```json
{
  "customer": {
    "gender": "Female",
    "SeniorCitizen": 0,
    "Partner": "Yes",
    "Dependents": "No",
    "tenure": 12,
    "PhoneService": "Yes",
    "MultipleLines": "No",
    "InternetService": "Fiber optic",
    "OnlineSecurity": "No",
    "OnlineBackup": "Yes",
    "DeviceProtection": "No",
    "TechSupport": "No",
    "StreamingTV": "Yes",
    "StreamingMovies": "No",
    "Contract": "Month-to-month",
    "PaperlessBilling": "Yes",
    "PaymentMethod": "Electronic check",
    "MonthlyCharges": 70.35,
    "TotalCharges": 840.50
  }
}
```

**Response:**
```json
{
  "prediction": "Yes",
  "prediction_label": 1,
  "churn_probability": 0.7245,
  "no_churn_probability": 0.2755,
  "confidence": 0.7245,
  "risk_level": "High"
}
```

### **3. Batch Prediction**
```bash
POST http://localhost:8000/predict/batch
```

**Request Body:**
```json
{
  "customers": [
    { /* customer 1 data */ },
    { /* customer 2 data */ }
  ]
}
```

**Response:**
```json
{
  "predictions": [ /* array of predictions */ ],
  "total_customers": 2,
  "high_risk_count": 1
}
```

### **4. Model Information**
```bash
GET http://localhost:8000/model/info
```

### **5. Feature Importance**
```bash
GET http://localhost:8000/model/feature-importance
```

---

## ğŸ§ª Testing the API

### Option 1: Interactive Docs (Recommended)
1. Start API server: `python run_api.py`
2. Open browser: http://localhost:8000/docs
3. Try out endpoints directly in the browser

### Option 2: Test Script
```bash
python test_api.py
```

### Option 3: cURL Commands
```bash
# Health check
curl http://localhost:8000/health

# Single prediction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d @sample_request.json
```

### Option 4: Python Requests
```python
import requests

response = requests.post(
    "http://localhost:8000/predict",
    json={"customer": {/* customer data */}}
)
print(response.json())
```

---

## ğŸ¨ Streamlit Dashboard Features

### **1. Single Prediction Tab**
- Interactive form for customer data
- Real-time prediction
- Probability gauge visualization
- Risk assessment
- Actionable recommendations

### **2. Batch Prediction Tab**
- CSV file upload
- Bulk predictions
- Results visualization
- Risk distribution charts
- Download results as CSV

### **3. Analytics Tab**
- Feature importance visualization
- Model performance metrics
- Top contributing features

---

## ğŸ“ Updated Project Structure

```
mlops-churn-prediction/
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ pipeline/
â”‚       â”œâ”€â”€ training_pipeline.py     # Phase 1
â”‚       â””â”€â”€ prediction_pipeline.py   # Phase 2 - NEW
â”‚
â”œâ”€â”€ api/                             # Phase 2 - NEW
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                      # FastAPI application
â”‚   â””â”€â”€ schemas.py                   # Pydantic models
â”‚
â”œâ”€â”€ streamlit_app/                   # Phase 2 - NEW
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ app.py                       # Streamlit dashboard
â”‚
â”œâ”€â”€ run_api.py                       # Phase 2 - NEW
â”œâ”€â”€ run_streamlit.py                 # Phase 2 - NEW
â””â”€â”€ test_api.py                      # Phase 2 - NEW
```

---

## ğŸ”§ Configuration

### API Configuration
The API automatically loads the best model from:
- Model: `artifacts/models/xgboost.pkl` (or your best model)
- Preprocessor: `artifacts/preprocessors/preprocessor.pkl`
- Label Encoder: `artifacts/preprocessors/preprocessor_label_encoder.pkl`

### Customizing Model Path
Edit `api/main.py` or `streamlit_app/app.py`:
```python
prediction_pipeline = PredictionPipeline(
    model_path="artifacts/models/your_model.pkl"
)
```

---

## ğŸ“Š API Documentation

### Auto-Generated Docs
- **Swagger UI**: http://localhost:8000/docs
  - Interactive API testing
  - Request/response examples
  - Schema validation

- **ReDoc**: http://localhost:8000/redoc
  - Clean, organized documentation
  - Better for reading/sharing

---

## ğŸ¯ Use Cases

### For Data Scientists
- Test model predictions interactively
- Analyze feature importance
- Debug model behavior
- Validate model performance

### For Business Users
- Get instant churn predictions
- Upload customer lists for bulk analysis
- View risk assessments
- Download results for CRM

### For Developers
- Integrate predictions into applications
- RESTful API for microservices
- Automated batch processing
- Real-time inference

---

## ğŸ” Example Workflows

### Workflow 1: Single Customer Analysis
1. Open Streamlit: http://localhost:8501
2. Go to "Single Prediction" tab
3. Fill in customer information
4. Click "Predict Churn"
5. Review risk level and recommendations

### Workflow 2: Batch Processing
1. Prepare CSV with customer data
2. Open Streamlit batch prediction tab
3. Upload CSV file
4. Review results and visualizations
5. Download predictions

### Workflow 3: API Integration
```python
import requests

def predict_churn(customer_data):
    response = requests.post(
        "http://localhost:8000/predict",
        json={"customer": customer_data}
    )
    return response.json()

# Use in your application
customer = {/* customer data */}
result = predict_churn(customer)
if result['risk_level'] == 'High':
    # Trigger retention campaign
    send_retention_offer(customer)
```

---

## ğŸ› Troubleshooting

### Issue: API won't start
```bash
# Check if port 8000 is already in use
lsof -i :8000  # Mac/Linux
netstat -ano | findstr :8000  # Windows

# Use different port
uvicorn api.main:app --port 8001
```

### Issue: Streamlit won't start
```bash
# Clear Streamlit cache
streamlit cache clear

# Use different port
streamlit run streamlit_app/app.py --server.port 8502
```

### Issue: Model not found
```bash
# Verify model exists
ls artifacts/models/

# Train model if missing
python scripts/train.py
```

### Issue: Import errors
```bash
# Reinstall dependencies
pip install --upgrade -r requirements.txt
```

---

## ğŸ“ˆ Performance

### API Response Times
- Health check: < 10ms
- Single prediction: < 200ms
- Batch prediction (100 customers): < 2s

### Optimization Tips
1. Use batch predictions for multiple customers
2. Keep model loaded in memory (not reloading)
3. Use async endpoints for concurrent requests
4. Add caching for repeated predictions

---

## ğŸ”’ Security Considerations

### For Production:
1. **Add Authentication**
   ```python
   from fastapi.security import HTTPBearer
   security = HTTPBearer()
   ```

2. **Rate Limiting**
   ```python
   from slowapi import Limiter
   limiter = Limiter(key_func=get_remote_address)
   ```

3. **HTTPS Only**
   - Use reverse proxy (nginx)
   - Add SSL certificates

4. **Input Validation**
   - Already implemented with Pydantic
   - Add additional business logic checks

5. **CORS Configuration**
   - Specify allowed origins
   - Remove wildcard in production

---

## ğŸ“ Next Steps

### Phase 3: Containerization
- Create Dockerfile for API
- Create Dockerfile for Streamlit
- Docker Compose setup
- Push to Docker Hub

### Phase 4: Testing
- Unit tests for prediction pipeline
- API endpoint tests
- Integration tests
- Load testing

### Phase 5: CI/CD
- GitHub Actions workflows
- Automated testing
- Automated deployment

### Phase 6: Cloud Deployment
- Kubernetes deployment
- AWS EKS setup
- Monitoring and logging

---

## âœ… Phase 2 Checklist

- âœ… Prediction pipeline implemented
- âœ… FastAPI REST API created
- âœ… Pydantic schemas for validation
- âœ… Streamlit dashboard built
- âœ… Single prediction functionality
- âœ… Batch prediction support
- âœ… Interactive visualizations
- âœ… API documentation (auto-generated)
- âœ… Health check endpoints
- âœ… Test scripts provided

---

## ğŸ‰ Success Criteria

Phase 2 is complete when:
1. âœ… API server starts without errors
2. âœ… All endpoints respond correctly
3. âœ… Streamlit dashboard loads
4. âœ… Single predictions work
5. âœ… Batch predictions work
6. âœ… Visualizations display correctly
7. âœ… API docs are accessible

---

**Phase 2 Complete! Ready to proceed to Phase 3?** ğŸš€

Let me know if you encounter any issues or want to move to containerization!