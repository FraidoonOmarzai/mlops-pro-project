{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37bebe2a",
   "metadata": {},
   "source": [
    "<h1 align=center>Data Ingestion</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40dd410a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\44787\\\\Desktop\\\\mlops-pro-project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d623e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "from src.logger import logger\n",
    "from src.exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448f10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    \"\"\"Configuration for data ingestion component.\"\"\"\n",
    "    raw_data_path: str\n",
    "    train_data_path: str\n",
    "    test_data_path: str\n",
    "    test_size: float = 0.2\n",
    "    random_state: int = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d534799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    \"\"\"\n",
    "    Handles data loading and splitting into train/test sets.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        \"\"\"\n",
    "        Initialize DataIngestion component.\n",
    "        \n",
    "        Args:\n",
    "            config: DataIngestionConfig object with paths and parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        logger.info(\"Data Ingestion component initialized\")\n",
    "    \n",
    "    def initiate_data_ingestion(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Load data and split into train/test sets.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (train_data_path, test_data_path)\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting data ingestion process\")\n",
    "        \n",
    "        try:\n",
    "            # Read the dataset\n",
    "            logger.info(f\"Reading dataset from {self.config.raw_data_path}\")\n",
    "            df = pd.read_csv(self.config.raw_data_path)\n",
    "            logger.info(f\"Dataset loaded successfully. Shape: {df.shape}\")\n",
    "            \n",
    "            # Basic info logging\n",
    "            logger.info(f\"Columns: {list(df.columns)}\")\n",
    "            logger.info(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "            logger.info(f\"Duplicates: {df.duplicated().sum()}\")\n",
    "            \n",
    "            # Create directory for processed data\n",
    "            os.makedirs(os.path.dirname(self.config.train_data_path), exist_ok=True)\n",
    "            \n",
    "            # Split the data\n",
    "            logger.info(f\"Splitting data with test_size={self.config.test_size}\")\n",
    "            train_set, test_set = train_test_split(\n",
    "                df,\n",
    "                test_size=self.config.test_size,\n",
    "                random_state=self.config.random_state,\n",
    "                stratify=df.iloc[:, -1] if 'Churn' in df.columns else None  # Stratify on target\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"Train set shape: {train_set.shape}\")\n",
    "            logger.info(f\"Test set shape: {test_set.shape}\")\n",
    "            \n",
    "            # Save train and test sets\n",
    "            train_set.to_csv(self.config.train_data_path, index=False, header=True)\n",
    "            test_set.to_csv(self.config.test_data_path, index=False, header=True)\n",
    "            \n",
    "            logger.info(\"Data ingestion completed successfully\")\n",
    "            logger.info(f\"Train data saved to: {self.config.train_data_path}\")\n",
    "            logger.info(f\"Test data saved to: {self.config.test_data_path}\")\n",
    "            \n",
    "            return (\n",
    "                self.config.train_data_path,\n",
    "                self.config.test_data_path\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(\"Error in data ingestion\")\n",
    "            raise CustomException(e, sys)\n",
    "    \n",
    "    def get_data_info(self) -> dict:\n",
    "        \"\"\"\n",
    "        Get information about the ingested data.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with data statistics\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(self.config.raw_data_path)\n",
    "            \n",
    "            info = {\n",
    "                'total_rows': len(df),\n",
    "                'total_columns': len(df.columns),\n",
    "                'columns': list(df.columns),\n",
    "                'missing_values': df.isnull().sum().to_dict(),\n",
    "                'duplicates': int(df.duplicated().sum()),\n",
    "                'dtypes': df.dtypes.astype(str).to_dict()\n",
    "            }\n",
    "            \n",
    "            return info\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd11d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_ingestion_config(config_dict: dict) -> DataIngestionConfig:\n",
    "    \"\"\"\n",
    "    Create DataIngestionConfig from dictionary.\n",
    "    \n",
    "    Args:\n",
    "        config_dict: Configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        DataIngestionConfig object\n",
    "    \"\"\"\n",
    "    return DataIngestionConfig(\n",
    "        raw_data_path=config_dict.data_ingeti.raw_data_path,\n",
    "        train_data_path=config_dict.train_data_path,\n",
    "        test_data_path=config_dict.test_data_path,\n",
    "        test_size=config_dict.test_size,\n",
    "        random_state=config_dict.random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc11c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-06 18:25:30,342] INFO - ChurnPrediction - yaml file: configs\\config.yaml loaded successfully\n",
      "[2025-11-06 18:25:30,356] INFO - ChurnPrediction - Data Ingestion component initialized\n",
      "[2025-11-06 18:25:30,357] INFO - ChurnPrediction - Starting data ingestion process\n",
      "[2025-11-06 18:25:30,358] INFO - ChurnPrediction - Reading dataset from data/raw/churn_data.csv\n",
      "[2025-11-06 18:25:30,426] INFO - ChurnPrediction - Dataset loaded successfully. Shape: (7043, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-06 18:25:30,429] INFO - ChurnPrediction - Columns: ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
      "[2025-11-06 18:25:30,442] INFO - ChurnPrediction - Missing values: 0\n",
      "[2025-11-06 18:25:30,476] INFO - ChurnPrediction - Duplicates: 0\n",
      "[2025-11-06 18:25:30,479] INFO - ChurnPrediction - Splitting data with test_size=0.2\n",
      "[2025-11-06 18:25:30,504] INFO - ChurnPrediction - Train set shape: (5634, 21)\n",
      "[2025-11-06 18:25:30,506] INFO - ChurnPrediction - Test set shape: (1409, 21)\n",
      "[2025-11-06 18:25:30,585] INFO - ChurnPrediction - Data ingestion completed successfully\n",
      "[2025-11-06 18:25:30,588] INFO - ChurnPrediction - Train data saved to: data/processed/train.csv\n",
      "[2025-11-06 18:25:30,589] INFO - ChurnPrediction - Test data saved to: data/processed/test.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from yaml import safe_load\n",
    "from src.utils.common import read_yaml\n",
    "\n",
    "try:\n",
    "    config_dict = read_yaml(Path(\"configs/config.yaml\"))\n",
    "    config = create_data_ingestion_config(config_dict.data_ingestion)\n",
    "    data_ingestion = DataIngestion(config)\n",
    "    train_data_path, test_data_path = data_ingestion.initiate_data_ingestion()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Data ingestion failed: {e}\")\n",
    "    raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529f844",
   "metadata": {},
   "source": [
    "<h1 align=center>Data Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfd40cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "from dataclasses import dataclass\n",
    "from src.logger import logger\n",
    "from src.exception import CustomException\n",
    "# from src.utils.common import save_json\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def save_json(path, data):\n",
    "    path = Path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b44a1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataValidationConfig:\n",
    "    \"\"\"Configuration for data validation component.\"\"\"\n",
    "    report_path: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2e0f837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(Path(\"data/raw/churn_data.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c17fc62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67caaca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidation:\n",
    "    \"\"\"\n",
    "    Validates data quality and schema compliance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Expected schema for churn dataset\n",
    "    EXPECTED_COLUMNS = [\n",
    "        'customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "        'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "        'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "        'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn'\n",
    "    ]\n",
    "    \n",
    "    ## type of TotalCharges is object\n",
    "    # NUMERICAL_COLUMNS = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "    NUMERICAL_COLUMNS = ['tenure', 'MonthlyCharges']\n",
    "    \n",
    "    CATEGORICAL_COLUMNS = [\n",
    "        'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService',\n",
    "        'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "        'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "        'Contract', 'PaperlessBilling', 'PaymentMethod'\n",
    "    ]\n",
    "    TARGET_COLUMN = 'Churn'\n",
    "    \n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        \"\"\"\n",
    "        Initialize DataValidation component.\n",
    "        \n",
    "        Args:\n",
    "            config: DataValidationConfig object\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        logger.info(\"Data Validation component initialized\")\n",
    "    \n",
    "    def validate_schema(self, df: pd.DataFrame) -> Dict[str, bool]:\n",
    "        \"\"\"\n",
    "        Validate if dataframe matches expected schema.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame to validate\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with validation results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            validation_results = {}\n",
    "            \n",
    "            # Check if all expected columns are present\n",
    "            missing_columns = set(self.EXPECTED_COLUMNS) - set(df.columns)\n",
    "            validation_results['all_columns_present'] = len(missing_columns) == 0\n",
    "            validation_results['missing_columns'] = list(missing_columns)\n",
    "            \n",
    "            # Check for extra columns\n",
    "            extra_columns = set(df.columns) - set(self.EXPECTED_COLUMNS)\n",
    "            validation_results['extra_columns'] = list(extra_columns)\n",
    "            \n",
    "            # Check data types for numerical columns\n",
    "            numerical_dtype_check = {}\n",
    "            for col in self.NUMERICAL_COLUMNS:\n",
    "                if col in df.columns:\n",
    "                    numerical_dtype_check[col] = pd.api.types.is_numeric_dtype(df[col])\n",
    "            validation_results['numerical_dtypes_correct'] = all(numerical_dtype_check.values())\n",
    "            validation_results['numerical_dtype_details'] = numerical_dtype_check\n",
    "            \n",
    "            logger.info(f\"Schema validation completed: {validation_results}\")\n",
    "            return validation_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "    \n",
    "    def validate_data_quality(self, df: pd.DataFrame) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Validate data quality checks.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame to validate\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with quality check results\n",
    "        \"\"\"\n",
    "        try:\n",
    "            quality_report = {}\n",
    "            \n",
    "            # Check for missing values\n",
    "            missing_values = df.isnull().sum()\n",
    "            quality_report['missing_values'] = missing_values[missing_values > 0].to_dict()\n",
    "            quality_report['total_missing'] = int(df.isnull().sum().sum())\n",
    "            quality_report['missing_percentage'] = round(\n",
    "                (df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100, 2\n",
    "            )\n",
    "            \n",
    "            # Check for duplicates\n",
    "            quality_report['duplicate_rows'] = int(df.duplicated().sum())\n",
    "            quality_report['duplicate_percentage'] = round(\n",
    "                (df.duplicated().sum() / len(df)) * 100, 2\n",
    "            )\n",
    "            \n",
    "            # Check for data ranges (numerical columns)\n",
    "            numerical_stats = {}\n",
    "            for col in self.NUMERICAL_COLUMNS:\n",
    "                if col in df.columns:\n",
    "                    numerical_stats[col] = {\n",
    "                        'min': float(df[col].min()),\n",
    "                        'max': float(df[col].max()),\n",
    "                        'mean': float(df[col].mean()),\n",
    "                        'std': float(df[col].std()),\n",
    "                        'negative_values': int((df[col] < 0).sum())\n",
    "                    }\n",
    "            quality_report['numerical_statistics'] = numerical_stats\n",
    "            \n",
    "            # Check target distribution\n",
    "            if self.TARGET_COLUMN in df.columns:\n",
    "                target_dist = df[self.TARGET_COLUMN].value_counts()\n",
    "                quality_report['target_distribution'] = target_dist.to_dict()\n",
    "                quality_report['target_balance_ratio'] = round(\n",
    "                    target_dist.min() / target_dist.max(), 2\n",
    "                )\n",
    "            \n",
    "            logger.info(f\"Data quality validation completed\")\n",
    "            return quality_report\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "    \n",
    "    def initiate_data_validation(self, train_path: str, test_path: str) -> bool:\n",
    "        \"\"\"\n",
    "        Perform complete data validation on train and test sets.\n",
    "        \n",
    "        Args:\n",
    "            train_path: Path to training data\n",
    "            test_path: Path to test data\n",
    "            \n",
    "        Returns:\n",
    "            Boolean indicating if data passed validation\n",
    "        \"\"\"\n",
    "        logger.info(\"Starting data validation process\")\n",
    "        \n",
    "        try:\n",
    "            # Load data\n",
    "            train_df = pd.read_csv(train_path)\n",
    "            test_df = pd.read_csv(test_path)\n",
    "            \n",
    "            logger.info(f\"Loaded train data: {train_df.shape}\")\n",
    "            logger.info(f\"Loaded test data: {test_df.shape}\")\n",
    "            \n",
    "            # Validate schema\n",
    "            train_schema = self.validate_schema(train_df)\n",
    "            test_schema = self.validate_schema(test_df)\n",
    "            \n",
    "            # Validate quality\n",
    "            train_quality = self.validate_data_quality(train_df)\n",
    "            test_quality = self.validate_data_quality(test_df)\n",
    "            \n",
    "            # Compile validation report\n",
    "            validation_report = {\n",
    "                'train_data': {\n",
    "                    'shape': train_df.shape,\n",
    "                    'schema_validation': train_schema,\n",
    "                    'quality_validation': train_quality\n",
    "                },\n",
    "                'test_data': {\n",
    "                    'shape': test_df.shape,\n",
    "                    'schema_validation': test_schema,\n",
    "                    'quality_validation': test_quality\n",
    "                },\n",
    "                'validation_passed': (\n",
    "                    train_schema['all_columns_present'] and \n",
    "                    test_schema['all_columns_present']\n",
    "                )\n",
    "            }\n",
    "            \n",
    "            # Save validation report\n",
    "            save_json(self.config.report_path, validation_report)\n",
    "            logger.info(f\"Validation report saved to: {self.config.report_path}\")\n",
    "            \n",
    "            # Log critical issues\n",
    "            if not validation_report['validation_passed']:\n",
    "                logger.warning(\"Data validation failed! Check the validation report.\")\n",
    "            else:\n",
    "                logger.info(\"Data validation passed successfully!\")\n",
    "            \n",
    "            return validation_report['validation_passed']\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(\"Error in data validation\")\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c3a780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_validation_config(config_dict: dict) -> DataValidationConfig:\n",
    "    \"\"\"\n",
    "    Create DataValidationConfig from dictionary.\n",
    "    \n",
    "    Args:\n",
    "        config_dict: Configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        DataValidationConfig object\n",
    "    \"\"\"\n",
    "    return DataValidationConfig(\n",
    "        report_path=config_dict.report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09ea3583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-06 18:39:38,973] INFO - ChurnPrediction - yaml file: configs\\config.yaml loaded successfully\n",
      "[2025-11-06 18:39:38,975] INFO - ChurnPrediction - Data Validation component initialized\n",
      "[2025-11-06 18:39:38,977] INFO - ChurnPrediction - Starting data validation process\n",
      "[2025-11-06 18:39:39,016] INFO - ChurnPrediction - Loaded train data: (5634, 21)\n",
      "[2025-11-06 18:39:39,018] INFO - ChurnPrediction - Loaded test data: (1409, 21)\n",
      "[2025-11-06 18:39:39,020] INFO - ChurnPrediction - Schema validation completed: {'all_columns_present': True, 'missing_columns': [], 'extra_columns': [], 'numerical_dtypes_correct': True, 'numerical_dtype_details': {'tenure': True, 'MonthlyCharges': True}}\n",
      "[2025-11-06 18:39:39,020] INFO - ChurnPrediction - Schema validation completed: {'all_columns_present': True, 'missing_columns': [], 'extra_columns': [], 'numerical_dtypes_correct': True, 'numerical_dtype_details': {'tenure': True, 'MonthlyCharges': True}}\n",
      "[2025-11-06 18:39:39,069] INFO - ChurnPrediction - Data quality validation completed\n",
      "[2025-11-06 18:39:39,088] INFO - ChurnPrediction - Data quality validation completed\n",
      "[2025-11-06 18:39:39,092] INFO - ChurnPrediction - Validation report saved to: artifacts/validation_report.json\n",
      "[2025-11-06 18:39:39,094] INFO - ChurnPrediction - Data validation passed successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config_dict = read_yaml(Path(\"configs/config.yaml\"))\n",
    "    data_validation_config = create_data_validation_config(config_dict.data_validation)\n",
    "    data_validation = DataValidation(data_validation_config)\n",
    "    validation_passed = data_validation.initiate_data_validation(\n",
    "        config_dict.data_ingestion.train_data_path,\n",
    "        config_dict.data_ingestion.test_data_path\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.error(f\"Data validation failed: {e}\")\n",
    "    raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faabdd1a",
   "metadata": {},
   "source": [
    "<h1 align=center>Data Preprocessing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f0c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlopspro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
